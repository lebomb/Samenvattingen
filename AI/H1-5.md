# Artificiële Intelligentie
## Hoofdstuk 1: Rationale Agenten
---
**Turing-test:**
> Operationele definitie van intelligentie opgesteld door Alan Turing in 1950. Een computer slaagt in de Turing-test wanneer een **menselijke ondervrager niet kan uitmaken** of de geschreven antwoorden van een **computer of een mens** afkomstig zijn.

Om voor deze test te slagen moet de computer volgende deelvelden van AI goed beheersen:

1. Goede beheersing van natuurlijke taal om vlot te kunnen communiceren.
2. Kennisrepresentatie om te kunnen opslaan wat hij weet of hoort.
3. Geautomatiseerd redeneren om de opgeslagen kennis te gebruiken om vragen te beantwoorden en zelf nieuwe conclusies te kunnen afleiden.
4. Machinaal leren om zich aan nieuwe omstandigheden of patronen te kunnen aanpassen.

In de uitgebreide Turing test beschikt de ondervrager over een camera om de perceptuele mogelijkheden van de ondervrager te testen, maar ook een luik om objecten door te geven aan de ondervrager. Voor deze test moet de computer naast bovenstaande vaardigheden ook de volgende beheersen: mogelijkheid om te zien en robotica om objecten te manipuleren.

**Rationale Agenten**
> Een **agent** is elke entiteit die zijn **omgeving** kan waarnemen aan de hand van zijn **sensoren** en die invloed kan uitoefenen op zijn omgeving aan de hand van zijn **actuatoren**

Een rationale agent moet ook beschikken over een performantiemaat, deze moet niet het gedrag, maar het gewenste resultaat belonen.

> Een **rationale agent** selecteert, voor elke mogelijke waarnemingssequentie, die actie waarvan verwacht wordt dat deze zijn **performantiemaat maximaliseert**, rekening houdend met het bewijs aangebracht door de huidige waarnemingssequentie en de eventuele ingeboudwde kennis van de agent.

**Eigenschappen van omgevingen**

1. **Compleet observeerbaar**: alle relevante aspacten zijn zichtbaar om een volgende actie te ondernemen.
2. **Partieel observeerbaar**
3. **Eenpersoons**: de agent handelt alleen in de omgeving
5. **Multipersoons**:  wanneer er meerdere agenten zijn.
    * **competitief**
    * **coöperatief**
        In sommige gevallen kunnen agenten beide gedragenvertonen.
5. **Deterministisch**: de volgende toestand van de omgeving wordt volledig bepaald door de huidige toestand en de actie die werd ondernomen door de agent.
6. **Stochastisch**: de volgende toestand van de omgeving wordt niet volledig bepaald door de huidige omgeving en de actie ondernomen door de agent. (bv. kansen)
7. **Episodisch**: de ervaring van de agent wordt opgedeeld in verschillende onafhankelijke episodes. De actie die wordt ondernomen in de huidige episode heeft *geen* invloed op de volgende episode.
8. **Sequentieel**: de huidige actie heeft wel een (potentiële) invloed op alle volgende acties.
9. **Statisch**: de omgeving wijzigt niet terwijl de agent nadenkt over zijn volgende actie.
10. **Dynamisch**: de omgeving wijzigt wel tijdens het nadenken.
11. **Discreet**: er zijn een eindig aantal toestanden.
12. **Continu**: er zijn een oneindig aantal mogelijke acties.

**Structuur van Agenten**
Op een hoog niveau worden agenten onderverdeeld in 4 types, deze zijn de volgende (in oplopende volgorde van complexiteit en  bruikbaarheid):

1. **Eenvoudige reflex:**
De agent heeft geen geheugen en neemt volgende actie enkel en alleen op basis van de **huidige waarneming** (**conditie-actie regel**, bv. ALS auto voor mij remt DAN rem).

2. **Modelgebaseerde reflex:**
De agent houdt een **inschatting** bij van wat de **huidige toestand** is, deze inschatting is in het algemeen *niet gelijk* aan de werkelijke toestand. De agent beschikt over een **model van de manier waarop de toestand wijzigt**, zowel onafhankelijk van de agent (bv. physics van de wereld) als door de acties van de agent zelf. Telkens wanneer een nieuze waarneming binnenkomt wordt de inschatting van de huidige toestand aangepast m.b.v. het model, de waarneming en de laatst ondernomen actie. **Daarna worden de conditie-actie regels** losgelaten op de inschatting van de huidige toestand.

3. **Doelgebaseerde: (= modelgebaseerde + doel + denken)**
De inschatting die gedaan wordt bij de modelgebaseerde reflex, of zelfs de volledige kennis van de huidige toestand, is niet steeds voldoende om te weten wat je moet doen. De agent heeft in deze situaties een **beschrijving van het doel** nodig. Hierbovenop **denkt** een doelgebaseerde agent ook **hoe de omgeving kan evolueren** op basis van zijn acties. Deze agent is veel **flexibeler** dan de modelgebaseerde, wanneer die een nieuwe bestemming wil geven moeten alle conditie-actie regels herschreven worden, voor de doelgebaseerde enkel de bestemming.  

4. **Utiliteitsgebaseerde: (= doelgebaseerde + performantie)**
Een doelgebaseerde agent is dichotoon: een toestand is een doeltoestand of niet en maakt dus geen onderscheid in performantie tussen deze toestanden. **Utiliteitsgebaseerde agenten** hebben een **utiliteitsfunctie** die **aangeeft hoe performant een toestand is** (~ internalistatie v.d performantiemaat). Wanneer utlititeitsfunctie en performantiemaat overeenkomen dan zal een utiliteitsgebaseerde agent die zijn utiliteit gaat maximaliseren ook meteen zijn performantiemaat gaan maximaliseren. Hierdoor is ze dus veel **flexibeler dan een doelgebaseerde agent**.

## Hoofdstuk 2: Zoekalgoritmes
----

### Inleiding
Een **zoekprobleem** bestaat uit volgende elementen:

* een **toestandsruimte S** die alle mogelijke toestanden bevat.
* een **verzameling** van mogelijke **acties**
* een **transitiemodel** dat zegt wat het effect is van het uitvoeren van een actie op een bepaalde toestand:

        T : (S, A) →  S : (s,a)  ↦ s'
    wanneer *s'* bereikt wordt door het uitvoeren van een actie *a* op een toestand *s* dan wordt *s'* een opvolger van *s* genoemd. (= Deterministische omgeving: wanneer *s* en *a* gekend zijn is er juist 1 opvolger: *s'*)
    Hetuitvoeren van een actie op een bepaalde toestand heeft meestal een bepaalde **kost**:

        C : (S, A) →  ℝ: (s,a)  ↦ c

* Een **initiële toestand** *sO* ∈ S, dit is de toestand van waaruit het zoeken zal vertrekken
* Een **doeltest**. Dit is een functie die voor elke toestand *s* aangeeft of het doel bereikt is of niet. Een toestand waarvoor de doeltest voldaan is noemen we een **doeltoestand**

De toestandsruimte *S* kan samen met de transitie- en kostfunctie gebruikt worden om een **toestandsruimtegraaf** *G* te maken. In deze graaf stellen knopen de toestanden voor en twee knopen zijn verbonden door een gerichte boog wanneer de ene knoop de opvolger is van de andere door het uitvoeren van een bepaalde actie. (kost boog = kost actie). **Elke toestand komt juist 1 keer voor.** (abstract concept: dergelijke graaf is veel te groot om bij te houden in het geheugen van een computer)

### Algemene Zoekalgoritmes
####Boomgebaseerd zoeken
Het algemene algoritme houdt een lijst bij van mogelijke partiële oplossingen die nog verder uitgewerkt (geëxpandeerd) moeten worden (= **open lijst**). Bij de start van de uitvoering bestaat deze open lijst enkel uit het plan corresponderend met de initiële toestand van het zoekprobleem. Bij elke iteratie van het algoritme wordt een plan uitgekozen uit deze lijst (volgens 1 of andere strategie) en wanneer de eindtoestand van het gekozen plan voldoet aan de doeltest, stopt het algoritme. Wanneer dit niet het geval is dan worden de plannen voor alle opvolgers van de eidntoestand van het gekozen plan toegevoegd aan de open lijst, waardoor deze ook beschikbaar worden voor expansie. Wanneer de open lijst op een bepaald moment leeg is dan geeft het algoritme aan dat er geen oplossing werd gevonden.
> Conceptueel bouwen we dus een **zoekboom** op, elke top van deze boom stelt een sequentie van acties voor. Het is dus de bedoeling zoekproblemen op te lossen met een zo klein mogelijke zoekboom. Elke top stelt dus een plan voor dat o.a. de huidige toestand bijhoudt, dezelfde toestand kan, en zal, in de het algemeen *meerdere malen* voorkomen in een zoekboom


**Algoritme:**

Invoer: Een zoekprobleem P.

Uitvoer:  Een sequentie van acties die een oplossing is van het zoekprobleem of error wanneer er geen oplossing werd gevonden.
```python
1: function TREESEARCH(P)
2:      f  <-  nieuwe lege lijst                                    > De open lijst
3:      f.ADD(nieuw plan gebaseerd op initiële toestand P)
4:      while f ≠ ∅ do
5:          c <- f .CHOOSEANDREMOVEPLAN                             > Kies het volgende plan
6:          if P.GOALTEST(c.GETSTATE) = true then
7:              return GETACTIONSEQ(c)
8:          else
9:              for (s, a) ∈ c.GETSTATE.GETSUCCESSORS do
10:                 f.ADD(nieuw plan gebaseerd op (s, a) en c)
11:             end for
12:         end if
13:     end while
14: return error: geen oplossing gevonden                           > Open lijst is leeg.
15: end function
```

**Implementatie van een plan**

Zoals reeds gezegd stelt elke top van de zoekboom een sequentie van acties voor, maar het is **niet nodig** om in elke top het **volledige pad op te slaan**. Door gebruik te maken van het **vorige pad in combinatie met de laatste gekozen actie**, kan je zo het volledige plan opstellen.

Voor de implementatie gebruiken we een klasse **Plan** dat bestaat uit **vier velden**:
1. **Huidige toestand**
2. **Laatst gekozen actie _a_**, deze is enkel leef voor het plan geassocieerd met de initiële toestand.
3. **Voorganger/ouder** van dit plan. Een referentie naar het plan waarvan dit plan is afgeleid door het toepassen van de huidige actie a.
4. **Totale kost _g_** van dit plan.  Strikt genomen kunnen we deze kost ook berekenen door het volgen van de voorganger-referenties, maar deze berekening heeft echter een uitvoeringstijd die lineair is in het aantal acties van het plan.

**Criteria voor Zoekalgoritmes**

Zoekalgoritmes kunnen op verschillende manieren worden geëvalueerd, deze vier worden vaak gebruikt:

1.  Een zoekalgoritme is **compleet** wanneer het algoritme, voor elk zoekprobleem met een oplissing, effectief een oplossing vindt.

2. Een zoekalgoritme is **optimaal**, wanneer het niet enkel *een* oplossing vindt, maar steeds een optimale oplossing teruggeeft voor elk zoekprobleem met een oplossing.

3. De **tijdscomplexiteit** van een zoekalgoritme bepaalt de uitvoeringstijd van het algoritme. We nemen aan dat de uitvoeringstijd evenredig is met het aantal gegenereerde toppen.

4. De **ruimtecomplexiteit** van een zoekalgoritme bepaalt de hoeveelheid geheugen die het algoritme nodig heeft tijdens de uitvoering. Dit wordt meestal uitgedrukt als het maximaal aantal toestanden dat gelijktijdig moet worden bijgehouden.

**Maten die gebruikt wordt om tijds- en ruimtecomplexiteit van zoekalgoritmes uit te drukken:**
* De **vertakkingsfactor _b_** geeft het maximaal aantal opvolgers van een top in de zoekboom.
* Een **doeltop_d_** (= diepte van de meest ondiepe top waarvan de toestand een doeltoestand is).
* De **maximale lengte _m_** is de maximale lengte (gemeten  als het aantal genomen acties) van een pad in de toestandsruimte.

Eigenschap: Het aantal toppen in een zoekboom met vertakkingsfactor *b* en maximale diepte *m* wordt gegeven door:
![alt text](http://users.hogent.be/~427143la/images/Eigenschap2-1.PNG "Eigenschap 2.1")

*Opmerking:* De laag met diepte *m* in een zoekboom met vertakkingsfactor *b* bevat *b^m* toppen, dit is meer dan alle voorgaande lagen samen. Die bevatten in totaal slechts:

![alt text](http://users.hogent.be/~427143la/images/Eigenschap2-2.PNG "Opmerking 2.1")

toppen.

#### Graafgebaseerd zoeken
Het grootste probleem van boomgebaseerd zoeken is dat dit algoritme **niet onthoudt waar het reeds geweest is**. Dit kan oneindige lussen veroorzaken, en in vele andere gevallen een grote hoeveelheid werk herhaaldelijk uitvoeren.

De oplossing hiervoor is gebruik maken van een **gesloten lijst** in plaats van een open lijst. Deze lijst onthoudt welke toestanden reeds geëxpandeerd zijn. **Let op!** Een gesloten lijst houdt **toestanden** bij, geen plannen zoals een open lijst.

> Bij graafgebaseerd zoeken wordt elke toestand **hoogstens 1 maal** geëxpandeerd. Wanneer een plan an de open lijst wordt gehaald dat een toestand bevat die reeds geëxpandeerd is, dan wordt deze niet opnieuw geëxpandeerd.

#### Algoritme

![alt text](http://users.hogent.be/~427143la/images/AlgoritmeGraafgebaseerd.PNG "Algoritme 2.1")

### Blinde Zoekmethoden
> Blinde Zoekmethoden kunnen enkel gebruikmaken van de informatie die verschaft wordt door de definitie van het zoekprobleem. Ze beschikken niet over extra informatie die hen kan helpen bij het zoekproces. Volgende zoekmethoden worden besproken:

#### Breedte Eerst Zoeken
> Bij breedte eerst zoeken wordt voor de open lijst een *wachtrij* gebruikt. Dit is een FIFO datastructuur. Bij breedte eerst zoeken wordt de zoekboom systematisch laag per laag opgebouwd, hierdoor zal het algoritme steeds een oplossing vinden voor elke zoekprobleem dat effctief een oplossing heeft. Dit betekent dat breedte eerst een **compleet zoekalgoritme** is. Het algoritme vindt steeds de meest ondiepe doeltop. (= *minimaal aantal acties*). Wanneer acties een *verschillende kost* hebben is dit dus *niet* noodzakelijk *de oplossing met de kleinste kost*, maar is dus wel optimaal wanneer elke actie dezelfde kost heeft.

Breedte eerst zoeken is **exponentieel in de diepte van de meest ondiepe doeltop**. Het maximaalaantal toppen dat moet worden bijgehouden in de open lijst wordt bereikt wanneer men de doeltop expandeert. Op dit moment wordt zo goed als de volledige laag op diepte *d* + 1 bijgehouden in de open lijst.

Bij **graafgebaseerd breedte eerst zoeken** kan men veel tijd winnen (tov boomgebaseerd) wanneer veel toestanden meerdere malen voorkomen in de zoekboom. Het extra geheugen dat men moet spenderen aan het bijhouden van de gesloten lijst weegt niet op tegen de tijdswinst die men kan maken. Om deze reden wordt **breedte eerst zoeken meestal uigevoerd in zijn graafgebaseerde versie**.

![alt text](http://users.hogent.be/~427143la/images/BreedteEerstZoeken.PNG "Breedte Eerst Zoeken")

#### Diepte Eerst zoeken
> Diepte eerst zoeken lijkt in zekere zin op breedte eerst zoeken, maar hier gebruikt men een **LIFO** structuur voor het bijhouden van de **open lijst**. Deze stapel zorgt ervoor dat men zo snel mogelijk zo diep mogelijk in de boom afdaalt.

Diepte eerst zoeken genereert steeds een **linkerdeel van de boom**. Wanneer *m* eindig is en de enige doeltop helemaal rechts onderaan in de boom zit, dan worden alle toppen van de boom gegenereerd. In het *slechtste geval* is de tijdscomplexiteit dus b^m. dit is dezelfde exponentiële tijdscomplexiteit als bij breedte eerst.

![alt text](http://users.hogent.be/~427143la/images/DiepteEerstZoeken.PNG "Diepte Eerst Zoeken")

In *bepaalde gevallen* kan diepte eerst zoeken toch in een **oneindige lus** geraken. Dus **diepte eerst zoeken is niet-compleet** en bijgevolg **niet optimaal**. Zelfs wanneer diepte eerst een oplossing vindt is deze niet gegarandeerd de optimale oplossing. (Meest linkse top kan dieper zijn dan een rechter doeltop).

**Diepte eerst scoort wel goed op _benodigd geheugen_**, wanneer een bepaalde top geëxpandeerd wordt behoren enkel de broers van zijn voorouders tot de open lijst. (maximaal tijdscomplexiteit: *m* niveaus x *b* broers -> lineair  -> veel beter dan exponentieel van breedte eerst)

#### Iteratief verdiepen
 > Iteratief verdiepen is geen directe toepassing van het boomgebaseerd zoekalgoritme dat hier reeds gegeven werd. In essentie is het een lus rond diepte-eerst zoeken waarbij het zoekproces wordt afgebroken wanneer een bepaalde diepte bereikt wordt. (= **Diepte Gelimiteerd Zoeken**)

 Volgend algoritme geeft een implementatie voor diepte-gelimiteerd zoeken.

![alt text](http://users.hogent.be/~427143la/images/IteratiefVerdiepenAlgoritme.PNG "Iteratief verdiepen")

Het algoritme heeft een bijzondere returnwaarde 'hit boundary' om aan te geven dat er geen oplossing werd gevonden binnen de opgegeven dieptelimiet, maar dat er wel *eventueel* een oplossing gevonden kan worden wanneer de maximale toegelaten diepte wordt verhoogd.

Dit gebeurt in volgend algoritme: **Iteratief Verdiepen**

![alt text](http://users.hogent.be/~427143la/images/IteratiefVerdiepenAlgoritme2.PNG "Iteratief verdiepen")

In tegen stelling tot wat je op eerste zicht zou denken, blijft de hoeveelheid extra werk beperkt. `Check Cursus 2.4`

Iteratief verdiepen is een **compleet zoekalgoritme** en zal steeds de oplossing met het minste aantal acties vinden. Het algoritme is in het algemeen niet optimaal buiten het geval dat alle acties de zelfde kost hebben. Het algoritme heeft een **exponentiële tijdscomplexiteit** maar slechts een lineaire ruimtecomplexiteit.

#### Uniforme Kost Zoeken
> Uniforme Kost Zoeken tracht het probleem dat breedte eerst heeft wanneer acties een verschillende kost hebben op te lossen door *steeds het plan te expanderen waarvoor de totale kost van dit plan minimaal is*. De **open lijst** wordt hier m.a.w. geïmplementeerd aan de hand van een **prioriteitswachtrij,** een kleinere kost betekent een grotere prioriteit. (~ Algoritme van Dijkstra)

Uniforme kost zoeken is (*wanneer alle acties een kost hebben die groter of gelijk aan één of andere positieve e is*)  een **compleet en optimaal algoritme**. De tijd- en ruimtecomplexiteit is *O(b^(1+C/e))*, waarbij *C* de kost van de optimale oplossing voorstelt.

### Geïnformeerde Zoekmethoden
> Geïnformeerde zoekmethoden gaan gebruik maken van een heuristiek om een goede indicator of schatting te hebben voor het zoekproces efficiënter te laten verlopen.

#### Heuristieken
Een heuristiek *h* is een afbeelding van de verzameling toestanden *S* naar de verzameling van niet-negatieve reële getallen R+, i.e.

        *h: S -> R+ : s -> h(s)*


#### Eigenschappen van Heuristieken
De heuristiek *h*: *S -> R+*:
* is **toelaatbaar** als voor elke toestand *s* geldt dat *h(s) <= C(S)* waarbij *C* de kost van een optimale oplossing voorstelt van *S* naar een doeltoestand.
        * Wanneer *h* toelaatbaar is, dan is *h(g) = 0* voor elke doeltoestand *g*.
* is **consistent** als voor elke doeltoestand *g* geldt dat *h(g) = 0* en als bovendien voor elke toestand *s* en elke actie *a* op *s* met *s' = T(s,a)* geldt dat:

![alt text](http://users.hogent.be/~427143la/images/consistent.PNG "consistent")

bv. Wanneer we de heuristiek beschouwen als "in vogelvlucht op doel afgaan" dan is een heuristiekconsitent wanneer het steeds korter is om in vogelvlucht op doel af te geen ( -> *h(s)*) dan om eerst een actie te ondernemen adhv het transitiemodel (*c(s,a,s')*) en dan in vogelvluchtop doel af te gaan (*h(s'*).

> Een *consistente heuristiek is altijd toelaatbaar*, maar dit wil niet zeggen dat elke toelaatbare heuristiek ook consistent is.

#### Gulzig Beste Eerst
> Gulzig Beste Eerst maakt gebruik van een heuristiek *h*, deze kiest steeds de top met de kleinste waarde van *h* als de volgende top die wordt geëxpandeerd. De **open lijst** wordt dus net als bij uniforme kost zoeken, geïmplementeerd als een **prioriteitswachtrij** en een kleinere waarde voor *h* betekent een grotere prioriteit.

Boomgebaseerd Gulzig Beste Eerst zoeken is **niet compleet**, zelfs niet met een consistente heuristiek. (Graafgebaseerd in een eindige toestandsruimte, zal het uiteraard wel altijd een oplossing vinden)

De tijd- en ruimtecomplexiteit zijn in het slechtste geval van de orde *b^m* (= **exponentieel**), maar kan door gebruik van een goede heuristiek sterk teruggedrongen worden.

#### A* Zoekalgoritme
> De *open lijst* wordt nog steeds geïmplementeerd als een **prioriteitswachtrij**, maar de volgende top die wordt geëxpandeerd is de top (plan) *n* waarvoor  **_f(n) = g(n) + h(n)_** minimaal is. Hierbij is *g(n)* de totale kost van het plan *n* en is *h(n)* de waarde van de heuristiek voor de toestand die hoort bij deze top.

Het gebruik van een *toelaatbare heuristiek* is voldoende om optimaliteit te garanderen wanneer men A* gebruikt in zijn boomgebaseerde versie (op voorwaarde dat alle acties een strikt positieve kost hebben). = **A* geeft steeds de meest optimale oplossing bij gebruik van een toelaatbare heuristiek**

Dit is **niet het geval bij graafgebaseerd zoeken**! Graafgebaseerd zoeken heeft een **consistente heuristiek** nodig om te garanderen dat A* compleet en optimaal is.

### Ontwerpen van Heuristieken
Het is duidelijk dat een goede heuristiek een grote positieve invloed heeft op de tijds- en ruimtecomplexiteit van een algoritme (zoals A*). We bekijken 2 manieren om een goede heuristiek te ontwerpen:

1. **Gebruik van Vereenvoudigde Problemen:** men gaat een heuristiek op stellen van het probleem, waarbij je de bestaande hindernissen negeert. Zo kan je bij een doolhof de muren wegdenken en vervolgens een heuristiek maken op basis van de manhattan afstand, hetzelde gaat bij de 8x8 puzzel waar dan de andere stukken weggedacht worden.

2.  **Patroon Databanken:** men gaat het probleem opdelen in deelproblemen om deze vervolgens op te slaan in een databank gelinkt met de oplossingskost voor elk deelprobleem. Het aanleggen van deze databank kan verveenvoudigd worden (omdat de acties omkeerbaar zijn) door graafgebaseerde breedte-eerst uit te voeren, startend vanaf het doelpatroon, en bij te houden wat de afstand is vanaf het doelpatroon dat gebruikt werd als initiële toestand. bv. 8x8 puzzel waarbij men het probleem gaat delen in 2, enkel de 1-4 wordt gebruikt, 5-8 worden sterretjes. Het kan ook omgekeerd, of zelf in combinatie (= dit geeft een betere heuristiek en is nog steeds aanvaardbaar.).

## Hoofdstuk 3: Zoeken met een Tegenstander
---
### Inleiding
> In dit Hoofdstuk bekijken we hoe een agent moet handelen om zijn performantiemaat te maximaliseren wanneer er in de omgeving nog een andere (competitieve) agent aanwezig is. Verder gaan we er van uit dat de **omgeving voor beide agenten compleet observeerbaar** is en dat er voor elke toestand slechts een **eindig aantal mogelijke deterministische acties** zijn. De agenten spelen om de beurt, zo'n omgeving wordt vaak *een spel* genoemd. De spelers van het spel noemen we *Max* en *Min*.

Enkele definities die we in dit hoofdstuk gaan gebruiken:
**Tweepersoons Nulsomspel**: wordt gespeeld door twee spelers en bestaat uit volgende componenten:
*  Een **verzameling toestanden _S_**
*  Een **verzameling mogelijke acties _A_**
* Een **transitiemodel** dat zegt wat het effect is van het uitvoeren van een actie op een bepaalde toestand:  **_T : (S,A) -> S : (s, a) -> s'_**.  Wanneer *s'* bereikt wordt door het uitvoeren van een actie *a* op een toestand *s* dan wordt *s'* een **opvolger** van *s* genoemd.
* De **initiële toestand _s0_**: deze bepaalt de toestand voor er een zet werd gedaan
* Een **eindtest** die voor een toestand aangeeft of het spel in deze toestand gedaan is of niet. De toestanden waarvoor de eindtest *true* teruggeeft worden eindtoestanden genoemd.
* Een **opbrengstfunctie _U_**: De functie *U* zegt voor elke eindtoestand en voor elke speler wat de opbrengst is in deze toestand voor de gegeven speler. Omdat het spel een nulsomspel is, geldt voor alle eindtoestanden *s* dat: **_U(s, Max) + U(s, Min) = K_**, waarbij *K* een constante is die hoort bij het spel.

###Spelbomen en het Minimax Algoritme
De initiële toestand *s0* bepaalt, samen met het transitiemodel *T* en de eindtest een **spelboom** voor het gegeven spel.
De wortel van de spelboom is de initiële toestand.
De kinderen van een top zijn de opvolgers van de toestand horend bij de top onder het gegeven transitiemodel.
De blaadjes van de boom corresponderen met de eindtoestanden van het spel.
De waarden die worden geschreven bij deze blaadjes corresponderen met de opbrengstfunctie vanuit het standpunt van de speler Max.

De spelboom is vooral een theoretisch concept, want voor realistische spellen is deze veel te groot om volledig op te bouwen en op te slaan in het geheugen.

bv. Tic Tac Toe:

![alt text](http://users.hogent.be/~427143la/images/TicTacToe.PNG "TicTacToeBoom")

Speler Max is als eerste aan de beurt en wil uiteraard die actie selecteren die
zijn opbrengst zo groot mogelijk zal maken. Wanneer het spel gedaan zou
zijn na één zet dan zou Max eenvoudigweg de waarde van de opbrengstfunctie
in de eindtoestanden kunnen gebruiken. Echter, Min is ook nog in
het spel en Max weet dat Min er alles aan gaat doen om de opbrengst voor
Max te minimaliseren, terwijl Max ook weet dat Min weet dat Max de opbrengst
voor zichzelf wil maximaliseren. We zien hier dus een recursief proces.
De MINIMAX WAARDE van een toestand wordt dus als volgt bepaald:

![alt text](http://users.hogent.be/~427143la/images/MiniMax.PNG "Minimax")

> Uiteraard beschouwen we in de toestand *s* enkel die acties *a* die zinvol kunnen uitgevoerd worden op de toestand *s*.

Eens de Minimax waarde van een toestand is bepaald is het eenvoudig om de gepaste actie voor Max te selecteren. *Men kiest eenvoudigweg die* **_actie waarvoor het maximum wordt bereikt._**

Die noemt men dan de **Minimax Beslissing**, dit is dus de beste beslissing wanneer er gespeeld wordt tegen een tegenstander die ook optimaal speelt. Een andere beslissing dan de minimax beslissing, kan en zal door een optimaal spelende tegenstader uitgebuit worden om ervoor te zorgen dat zijn eigen opbrengst zal stijgen, of gelijk blijven.

#### Minimax Algoritme
`Voor toelichting check cursus Algoritme 3.1`

![alt text](http://users.hogent.be/~427143la/images/MinimaxAlgoritme.PNG "Minimax Algoritme")


### Snoeien van Spelbomen
Bij een spelboom is *niet elke waarde relevant* voor het eindresultaat:

We berekenen de minimax waarde van toestand a. We vinden:

        minimax(a) = max(minimax(b), minimax(c), minimax(d))
                   = max(min(12, 3, 8), min(1, 5, 7), min(14, 5, 1))
                   = max(3, 1, 1)
                   = 3.

Veronderstel nu dat de laatste twee opvolgers van toestand *c* onbepaalde
waarden *x* en *y* hebben. In dit geval vinden we voor de minimax waarde van *a*:

        minimax(a) = max(minimax(b), minimax(c), minimax(d))
                   = max(min(12, 3, 8), min(1, x, y), min(14, 5, 1))
                   = max(3, z, 1)                                      (met z ≤ 1)
                   = 3

Dus wat *x* en *y* ook zijn, de minimaxwaarde van *a* blijft 3, merk op dat het niets uitmaakt dat de laatste twee opvolgers van *c* eindtoestanden zijn. De redenering gaat ook op als *x* en *y* het gevolg zijn van een spel met duizenden mogelijke zetten, in dit geval kan er dus veel tijd bespaard worden door deze takken van de spelboom niet te evalueren.

> Het **niet evalueren van een tak** in een spelboom wordt het **snoeien** (Eng: pruning) van die tak genoemd.

We wensen nu het minimax algoritme aan te passen om te kunnen snoeien waar mogelijk. Het minimax algoritme is een diepte eerst algoritme, dus op elk moment bekijken we 1 enkel pad in de spelboom. Het resulterende algoritme wordt **_a_ - _B_ snoeien** genoemd naar de 2 extra parameters die worden bijgehouden tov het minimax algoritme.


1. De **parameter _a_** (alfa) houdt de **waarde bij van de beste keuze** *(hoogste waarde)* op het huidige pad voor **Max**.
2. De **parameter _b_** (beta) houdt de **waarde bij van de beste keuze** (laagste waarde) op het huidige pad voor **Min**.


Max wijzigt de *a*-waarde en Min de *B*-waarden. Op elk moment heeft de top in de spelboom een **huidige waarde *v***;
Deze waarde **stijgt voor Max en daalt voor Min**.

Er kan gesnoeid worden als aan 1 van volgende voorwaarde voldaan is:

* **Min** merkt dat de **huidige waarde** *v* **kleiner of gelijk aan _a_** is. Een rationele Max zal immers het spel nooit hier laten komen aangezien hij op het huidig pad reeds een betere keuze heeft.
* **Max** merkt dat de **huidig waarde** *v* **groter of gelijk aan _B_** is. Een rationele Min zal immers het spel nooit hier laten komen aangezien hij op het huidig pad reeds een betere keuze heeft.

**Algoritme: Berekenen van de Minimax beslissing mbv _a_ - _B_ snoeien.**

![alt text](http://users.hogent.be/~427143la/images/ABSnoeienAlgoritme.JPG "AB Snoeien")

`Beschrijving uitwerking algoritme check cursus Voorbeeld 3.10 en verder.`



### Praktische Uitwerking

In veel spelbomen komt dezelfde toestand meerdere malen voor, dit leidt tot veel extra werk. Een oplossing bestaat erin om de toestanden, en hun minimax waarde, bij te houden in een hashtabel analoog aan de gesloten lijst bij graafgebaseerd zoeken.

Deze hashtabel wordt in de context van spelbomen de **transpositie tabel** genoemd. Het bijhouden van deze lijst kan een grote tijdswinst betekenen. Als het aantal toestanden te groot is, dan is het natuurlijk onmogelijk om alle toestanden bij te houden, maar er bestaan strategieën om te beslissen welke er wel bijgehouden worden.

In de praktijk stelt men een limiet in op de diepte (= het aantal halve zetten) van de boom. Wanneer die diepte wordt bereikt voordat een eindtoestand wordt bereikt, dan gebruikt men een **heuristische evaluatiefunctie** om de waarde van die toestand te benaderen.

We krijgen dan volgende **recursieve formule** om deze **heuristische minimax waarde** te berekenen voor maximale diepte *d*:

![alt text](http://users.hogent.be/~427143la/images/RecForHeur.JPG "Recursieve Formule Heuristische Minimax")

Om te voorkomen dat deze *heuristische evaluatiefunctie* het algoritme ongewenst in de richting van slechte posities stuurt, moet deze voldoen aan volgende **eigenschappen.**

Een **goede heuristische evaluatiefunctie**:
* Ordent eindtoestanden op dezelfde manier als de opbrengst functie *U*: de toestanden met winst moeten beter geëvalueerd worden dan de toestanden waarin er verloren wordt.
* Kan snel berekend worden, aangezien het de bedoeling is tijd te winnen.
* de waarde voor niet-eindtoestanden moet sterk gecorelleerd zijn met de kans om effectief te winnen vanuit die toestand.

`Voorbeeld evaluatiefunctie en spelboom uitgewerkt in cursus Voorbeeld 3.11`

## Hoofdstuk 4 : Lokaal Zoeken en Genetische Algoritmen
---

## Lokale Zoekmogelijkheden
> Worden gebruikt wanneer het **oplossingspad irrelevant** is aangezien deze zich niet bezig houdt met het oplossingspad maar met het toestanden. Dergelijke algoritmen houden dus 1 (of een beperkt aantal) huidige toestand bij en vervangen in het algemeen deze huidige toestand door 1 van zijn opvolgers in de hoop zo een *optimale* toestand te bereiken.

Hoewel lokale zoekmethoden minder systematisch zijn dan de reeds besproken Zoekalgoritmes, hebben ze twee grote voordelen:

1. Ze gebruken een beperkte (constante) hoeveelheid geheugen
2. Ze kunnen vaak redelijk goede oplossingen (= toestanden) vinden in zeer grote of continue toestandsruimten waar de systematische zoekalgoritmes falen.

**Lokale zoekalgoritmes** worden dus voornamelijk gebruikt voor **optimalisatieproblemen** waar er een doelfunctie is die met elke toestand een waarde associeert. Uitgeschreven:

*h* : *S* -> R : *s* -> *h(s)*

Het is deze doelfunctie die geoptimaliseerd moet worden.

### Globaal Maximum
Een toestand *s* is een **globaal maximum** voor een doelfunctie *h* als **voor alle toestanden** *s'* uit *S* geldt dat:

*h(s)* >= *h(s')*

### Lokaal Maximum
Een toestand *s* is een **lokaal maximum** voor een doelfunctie *h* als **voor alle opvolgers** van *s'* geldt dat:

*h(s)* >= *h(s')*

*Gelijkaardige definities gelden voor globaal en lokaal minimum*


Elk maximalisatieprobleem kan echter omgezet worden in een equivalent minimalisatieprobleem en omgekeerd. Bijvoorbeeld door de negatie te nemen van de doelfunctie en omgekeerd. Dit betekent dat het geen beperking is om de algoritmen slechts op 1 manier te schrijven.

### Hill Climbing
Hill climbing is het meest eenvoudige zoekalgoritme, het algoritme start in een willekeurige begintoestand en in elke iteratie vervangt het deze toestand door de beste toestand onder zijn opvolgers op voorwaarde dat deze beter is. Het algoritme stopt wanneer er geen verbetering meer mogelijk is.

Voordelen: **eenvoudig en snel**, en het kan initieel (vanuit een slechte toestand) vaak snel vooruitgang boeken.

#### Algoritme
![alt text](http://users.hogent.be/~427143la/images/AlgoritmeHillClimbing.PNG "HillClimbing")

Er zijn verschillende redenen waarom hill climbing kan falen in het vinden van een globaal maximum:

        * Lokale maxima: het hill climbing algoritme loopt cast wanneer een lokaal maximum wordt bereikt omdat in zo'n lokaal maximum geen enkele opvolger strikt beter is.
        * Plateaus: een plateau is een 'vlak stuk' in het landschap, in bovenstaande implementatie wordt er niet verder gegaan wanneer de beste opvolger even goed is als de huidige toestand. Men kan het algoritme wel eenvoudig aanpassen om wel zo'n zijwaartse stap te nemen. Hierbij moet men echter maatregelen nemen om te voorkomen dat het algoritme vastraakt in een oneindige lus (op zo'n plateau), Bijvoorbeeld wanneer de acties omkeerbaar zijn. De eenvoudigste manier om dit op te lossen is om het aantal toegelaten zijwaartse stappen te beperken.

> Het is duidelijk dat Hill Climbing **geen compleet** algoritme is, het vindt niet steeds een globaal optimum. Echter, door gebruik te maken van *random herstarten* kan het algoritme compleet worden gemaakt met waarschijnlijkheid 1. Dit laatste is vooral van theoretisch belang, in de praktijk kan het veel te lang duren voor effectief een globaal optimum wordt bereikt.

### Simulated Annealing

In elke iteratie wordt een random opvolger gegenereerd: wanneer deze strikt beter is dan de huidige oplossing dan wordt deze steeds aanvaard als nieuwe huidige toestand. Wanneer de random opvolger niet beter is dan de huidige oplossing dan aanvaarden we deze met een zekere waarschijnlijkheid. Deze waarschijnlijkheid wordt beinvloed door 2 twee factoren. Ten eerste is er het tijdstip in het algoritme en ten tweede is er de mate waarin de potentiële opvolger slechter is dan de huidige toestand.

De aanvaardingswaarschijnlijkheid daalt naarmate het algoritme vordert: in het begin zijn we tamelijk bereid om neerwaartse stappen te zetten maar naarmate het einde dichterbij komt, worden we meer weigerachtig om neerwaartse stappe te zetten.

![alt text](http://users.hogent.be/~427143la/images/Aanvaardingswaarschijnlijkheid.PNG "Aanvaardingswaarschijnlijkheid")

Op hetzelfde tijdstip in het algoritme is de waarschijnlijkheid ook kleiner wanneer de opvolger minder goed is, anders gezegd: **hoe slechter de opvolger hoe kleiner de kans om deze te aanvaarden.**

#### Algoritme
![alt text](http://users.hogent.be/~427143la/images/SimulatedAlgoritme.PNG "Simulated Annealing")

`Bekijk voorbeeld cursus 4.1.2`

### Gradient Descent

`Bekijk in Cursus`

## Genetische Algoritmen

Bij de klassieke zoekalgoritmen wordt een open lijst bijgehouden die al snel veel te groot wordt. Aan de andere kant zijn hill climbing en simulated annealing misschien iets te ver in de andere rihting doorgeslagen, in die zin dat ze slechts 1 toestand bijhouden.

### Populatie en Encodering

### Fitnessfunctie en Selectiemechanisme

### Recombinatie en Mutatie

### Eenvoudige implementatie

### Besluit en Toepassingen

## Hoofdstuk 5: Machinaal Leren
---

### Machinaal Leren
> Het deelveld van de artificiële intelligentie dat computers de **mogelijkheid geeft om te leren zonder dat ze hiervoor _expliciet_ geprogrammeerd zijn**.  

### 3 Types van Machinaal Leren

1. **Gesuperviseerd Leren:** op basis van een **gelabelde dataset** een **hypothese** op bouwen waarmee, voor een nieuwe invoer het label kan voorspeld worden.
    * Wanneer dit label een (reëel) getal is, dan spreekt men van een **Regressieprobleem**.
    * Wanneer het label 1 van een (klein) aantal voorgedefinieerde klassen is dan spreekt men van een **Classificatieprobleem**.
    In hetgeval dat er slechts 2 klassen zijn, spreekt men van een **binair** classificatieprobleem.

    ![alt text](http://users.hogent.be/~427143la/images/GesuperviseerdSchema.JPG "Schema")

2. **Ongesuperviseerd Leren**: heeft de taak een **structuur te ontdekken** in een **ongelabelde** dataset. Voorbeelden:
    * **Clustering**: Het ontdekken van coherente groepen. (= Meest voorkomende)
    * **Anomaliedetectie**: Het ontdekken van zaken die niet conform zijn met het verwacht patroon of andere zaken in de dataset.
    * **Primaire Componenten Analyse**

3. **Reinforcement Learning**: Werkt in plaats van datasets met **beloningssignalen**, die negatief zijn wanneer de agent een “slechte” handeling stelt en positief wanneer de agent een goede handeling stelt. Eenvoudig gezegd bestaat de taak van reinforcement learning erin om te **leren welke acties**, i.e. welk beleid, **leiden tot de hoogste totale beloning.**


### Evaluatie van Hypothesen voor Gesuperviseerd Leren.
#### Foutmaten
Om gemakkelijk verschillende hypothesen te vergelijken gebruikt men vaak een *numerieke maat* voor de fout over een verzameling van voorbeelden. Kleinere numerieke waarden duiden (meestal) op betere hypothesen.

Voor een **Regressieprobleem** neemt men als maat voor de fout vaak de **Gemiddelde kwadratische afwijking** tussen de voorspelde labels en de werkelijke labels over de verzameling voorbeelden.

In formulevorm:
![alt text](http://users.hogent.be/~427143la/images/Form1.JPG "Formule")

Voor een **Classificatieprobleem** gebruikt men vaak de **Foutratio**, dit is het percentage voorbeelden dat het verkeerde label toegewezen krijgt.

In formulevorm:
![alt text](http://users.hogent.be/~427143la/images/Form2.JPG "Formule")

Voor een **Binair Classificatieprobleem**, waar er een zeer scheve verdeling is tussen de klassen, is de **foutratio niet altijd de meest geschikte** manier om een hypothese te evalueren.
  * bv: Veronderstel dat men een hypothese heeft opgezet om te voorspellen of iemand een kwaadaardige kanker (y=1) heeft ofniet (y=0). Stel dat de foutratio over een bepaalde verzameling patiënten gelijk is aan 1%, of anders gezegd, we krijgen de juiste diagnose in 99% vande gevallen. Op het eerste zicht lijkt deze hypothese het echt goed te doen.Echter, als je weet dat er slechts een half procent van de patiënten in de dataset effectief kanker heeft dan heeft een triviaal algoritme dat steeds y=0 voorspelt, zonder naar de attributen te kijken, een foutratio van slechts een half procent! Het is duidelijk dat in zo’n geval de foutratio niet geschiktis.

We bekijken nu eventjes de vier verschillende uitkomsten die kunnen voor-komen bij een binair classificatieprobleem:

/ | y = 1 | y = 0
--- | --- | ---
h(*x*)=1 | correct (*a*) | vals positief (*b*)
h(*x*)=0 | vals negatief (*c*) | correct (*d*)

De **Precisie** zegt welk percentage van de voorbeelden die voorspeld waren als positief, ook effectief positief waren:

 ![alt text](http://users.hogent.be/~427143la/images/Form3.JPG "Formule")

De **Rappel** (Eng: recall) zegt welk percentage van de positieve voorbeelden ook effectief als positief werd gelabeld door de hypothese:

![alt text](http://users.hogent.be/~427143la/images/Form4.JPG "Formule")

**Een algoritme dat alle voorbeelden het correcte label geeft, heeft steeds een  precisie en rappel die allebei gelijk zijn aan 1.** Een algoritme dat steeds *h(x)=1* voorspelt heeft een rappel die gelijk is aan 1 (want alle positieve voorbeelden werden als positief voorspeld), maar de precisie is in dit geval slechts gelijk aan het percentage positieve voorbeelden in de dataset. Om de precisie te verhogen is het dus nodig om ook het label *0* te gaan voorspellen, maar dan loop je uiteraard het risico dat de rappel daalt.

Het is vaak interessant om de performantie van een hypothese te kunnen uitdrukken als één enkel getal. De precisie en de rappel kunnen gecombineerd worden in één enkele score, de **_F_ -score**:

 ![alt text](http://users.hogent.be/~427143la/images/Form5.JPG "Formule")

 > In dit geval zijn **grotere waarden** voor precisie, rappel en de F-score beter dan kleinere waarden.

 > Het gemiddelde nemen van de precisie en de rappel leidt **niet** tot een goede maat om hypothesen te vergelijken.

#### Trainings-, Validatie- en Testdata
 Eens we een maat gekozen hebben rijst de vraag voor welke verzameling we deze maat wensen te optimaliseren. We wensen een hypothese die het goed doet op nieuwe ongeziene voorbeelden. Dus een hypothese die de voorbeelden uit de traingsdataset **generaliseert** en er de patronen in herkent.

 > Het is foutief om te veronderstellen dat een hypothese die zeer goed scoort op de trainingsvoorbeelden ook onmiddelijk goed zal scoren op neuwe ongeziene voorbeelden.

 Om in te schatten hoe goed een hypothese scoort op nieuwe data gebruiken we een verzameling gelabelde voorbeelden die de **testdata** wordt genoemd.

 `Het is van uiterst belang dat deze testdate op geen enkele manier wordt gebruikt bij het opstellen van de hypothese`

 Een hypothese die zeer goed scoort op de trainingsdata maar die slecht scoort op de testadata leidt aan **overfitting**.
 Om overfitting te vermijden gebruiken sommige modellen meta-parameters of moet er beslist worden wanneer een iteratief trainingsproces wordt gestopt. Bij deze beslissing mag geen gebruik gemaakt worden van de testdata, daarom gebruikt men vaak nog een (derde) dataset die dan de **validatiedataset** wordt genoemd.

  ![alt text](http://users.hogent.be/~427143la/images/OverfittingGrafiek.PNG "OverfittingGrafiek")

  Overfitting begint wanneer de fout op de validatiedataset begint te stijgen. De blauwe lijn stelt de fout voor op de trainingsdata, normaalgezien daalt deze naarmate de training vordert of naarmate het model complexer wordt. Het beste model wordt dus wellicht verkregen op het moment dat de foutmaat op de **validatiedataset** minimaal wordt. *De uiteindelijke schatting voor de foutmaat moet echter gedaan worden adhv een derde dataset: de testdate. Maar deze mag op geen enkel moment gebruikt worden tijdens de trainingsfase*

 Wanneer de klassen van hypothesen waaruit gekozen kan worden niet groot genoeg is om een hypothese te vinden die goed generaliseert spreken we van **onderfitting**.

#### Ockhams Scheermes:
 Wanneer er moet gekozen worden tussen twee of meer modellen die de data goed verklaren dan moet men het meest eenvoudig model kiezen.
